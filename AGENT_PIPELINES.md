# CodeGeeX Agent Pipelines Documentation

Полная документация всех пайплайнов и схем работы агента CodeGeeX. Каждый пайплайн описан с детальными схемами потока данных, используемыми промтами и точками интеграции.

## Оглавление

1. [Пайплайн генерации кода (Code Generation Pipeline)](#1-пайплайн-генерации-кода)
2. [Пайплайн перевода кода (Code Translation Pipeline)](#2-пайплайн-перевода-кода)
3. [Пайплайн оценки бенчмарков (Benchmark Evaluation Pipeline)](#3-пайплайн-оценки-бенчмарков)
4. [Пайплайн веб-интерфейса (Web UI Pipeline)](#4-пайплайн-веб-интерфейса)
5. [Общая архитектура системы](#5-общая-архитектура-системы)

---

## 1. Пайплайн генерации кода

### Описание
Основной пайплайн для генерации кода на основе естественноязыкового описания или начального контекста кода. Используется в интерактивном режиме, веб-интерфейсе и бенчмарках.

### Точки входа

1. **Интерактивный режим / Тестирование**
   - **Файл:** `tests/test_inference.py`
   - **Функция:** `main()` (строка 118)
   - **Вызов:** `codegeex.generate()` (строка 167)

2. **Веб-интерфейс Gradio**
   - **Файл:** `deployment/server_gradio.py`
   - **Функция:** `predict()` (строка 108)
   - **Вызов:** `codegeex.generate()` (строка 121)

3. **Распределенная генерация для бенчмарков**
   - **Файл:** `codegeex/benchmark/humaneval-x/generate_humaneval_x.py`
   - **Функции:** `main()` (строка 202), `run_generation_distributed()` (строка 244)

### Схема потока данных

```
┌─────────────────────────────────────────────────────────────────────┐
│                         ПОЛЬЗОВАТЕЛЬСКИЙ ВВОД                        │
│                                                                      │
│  "Write a function to calculate factorial of n"                     │
│  или                                                                 │
│  "def factorial(n):\n    # Calculate factorial"                     │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 1: ОБРАБОТКА ПРОМТА                          │
│                    (Optional Language Tagging)                       │
│                                                                      │
│  Файл: codegeex/data/data_utils.py:7-64                            │
│  Функция: LANGUAGE_TAG[language]                                     │
│                                                                      │
│  Вход: prompt = "def factorial(n):"                                 │
│  Выход: "# language: Python\ndef factorial(n):"                     │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 2: ТОЧКА ВХОДА ГЕНЕРАЦИИ                     │
│                                                                      │
│  Файл: codegeex/__init__.py:15-69                                   │
│  Функция: generate()                                                 │
│                                                                      │
│  Параметры:                                                          │
│    - model: CodeGeeXModel                                            │
│    - tokenizer: CodeGeeXTokenizer                                    │
│    - prompt: str                                                     │
│    - out_seq_length: int (длина генерации)                          │
│    - seq_length: int (максимальная длина контекста, 2048)           │
│    - top_k: int (фильтрация top-k токенов)                          │
│    - top_p: float (nucleus sampling порог)                           │
│    - temperature: float (температура сэмплирования)                  │
│    - micro_batch_size: int (размер батча)                           │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 3: ТОКЕНИЗАЦИЯ                               │
│                                                                      │
│  Файл: codegeex/__init__.py:29                                      │
│  Метод: tokenizer.encode_code(prompt)                                │
│                                                                      │
│  Процесс:                                                            │
│    1. Разбиение текста на токены (GPT2-BPE алгоритм)                │
│    2. Преобразование токенов в ID                                    │
│    3. Сохранение длины промта: n_token_prompt                        │
│                                                                      │
│  Вход: "# language: Python\ndef factorial(n):"                      │
│  Выход: [3654, 3203, 25, 13814, 198, 4299, 1109, orial, 7, 77, ...] │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 4: СОЗДАНИЕ ПОТОКА ТОКЕНОВ                   │
│                                                                      │
│  Файл: codegeex/torch/inference.py:158-210                          │
│  Функция: get_token_stream()                                         │
│                                                                      │
│  Подготовка батча:                                                   │
│    pad_batch() - дополнение до seq_length токенами EOS              │
│    get_batch() - создание CUDA тензоров и attention masks           │
│                                                                      │
│  Создание attention mask (причинная маска):                          │
│    ┌─ 1  0  0  0  0 ─┐                                              │
│    │  1  1  0  0  0  │  Нижнетреугольная матрица                    │
│    │  1  1  1  0  0  │  1 = токен виден                             │
│    │  1  1  1  1  0  │  0 = токен замаскирован                      │
│    └─ 1  1  1  1  1 ─┘                                              │
│                                                                      │
│  Position IDs: [0, 1, 2, 3, 4, ..., seq_length-1]                   │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 5: АВТОРЕГРЕССИВНАЯ ГЕНЕРАЦИЯ                │
│                                                                      │
│  Файл: codegeex/torch/inference.py:217-327                          │
│  Функция: sample_sequence_batch()                                    │
│                                                                      │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │  ЦИКЛ ГЕНЕРАЦИИ (context_length <= maxlen)                 │    │
│  │                                                              │    │
│  │  ┌─────────────────────────────────────────────────────┐   │    │
│  │  │  5.1. FORWARD PASS                                   │   │    │
│  │  │                                                       │   │    │
│  │  │  model(tokens, position_ids, attention_mask,         │   │    │
│  │  │        layer_past, get_key_value=True)               │   │    │
│  │  │                                                       │   │    │
│  │  │  Режимы:                                             │   │    │
│  │  │    - Recompute: обработка всей последовательности    │   │    │
│  │  │    - KV Cache: обработка только новых токенов        │   │    │
│  │  │                                                       │   │    │
│  │  │  Выход: logits [batch_size, vocab_size]              │   │    │
│  │  │          layer_past (KV cache для эффективности)     │   │    │
│  │  └─────────────────────────────────────────────────────┘   │    │
│  │                          ▼                                  │    │
│  │  ┌─────────────────────────────────────────────────────┐   │    │
│  │  │  5.2. ОБРАБОТКА ЛОГИТОВ                             │   │    │
│  │  │                                                       │   │    │
│  │  │  a) Фильтрация нежелательных ID (bad_ids)           │   │    │
│  │  │     logits[bad_ids] = -10000                         │   │    │
│  │  │                                                       │   │    │
│  │  │  b) Применение температуры                           │   │    │
│  │  │     logits = logits / temperature                    │   │    │
│  │  │                                                       │   │    │
│  │  │  c) Top-k фильтрация                                 │   │    │
│  │  │     - Сортировка логитов                             │   │    │
│  │  │     - Оставить только top-k                          │   │    │
│  │  │     - Остальные = -inf                               │   │    │
│  │  │                                                       │   │    │
│  │  │  d) Top-p (nucleus) фильтрация                       │   │    │
│  │  │     - Softmax для получения вероятностей             │   │    │
│  │  │     - Сумма вероятностей до достижения top_p        │   │    │
│  │  │     - Токены вне ядра = -inf                         │   │    │
│  │  └─────────────────────────────────────────────────────┘   │    │
│  │                          ▼                                  │    │
│  │  ┌─────────────────────────────────────────────────────┐   │    │
│  │  │  5.3. СЭМПЛИРОВАНИЕ ТОКЕНА                          │   │    │
│  │  │                                                       │   │    │
│  │  │  probs = softmax(logits)                             │   │    │
│  │  │  next_token = multinomial(probs, num_samples=1)      │   │    │
│  │  │                                                       │   │    │
│  │  │  Альтернатива (greedy):                              │   │    │
│  │  │  next_token = argmax(logits)                         │   │    │
│  │  └─────────────────────────────────────────────────────┘   │    │
│  │                          ▼                                  │    │
│  │  ┌─────────────────────────────────────────────────────┐   │    │
│  │  │  5.4. ОБНОВЛЕНИЕ ПОСЛЕДОВАТЕЛЬНОСТИ                 │   │    │
│  │  │                                                       │   │    │
│  │  │  tokens[:, context_length] = next_token              │   │    │
│  │  │  context_length += 1                                 │   │    │
│  │  └─────────────────────────────────────────────────────┘   │    │
│  │                          ▼                                  │    │
│  │  ┌─────────────────────────────────────────────────────┐   │    │
│  │  │  5.5. ПРОВЕРКА ЗАВЕРШЕНИЯ                           │   │    │
│  │  │                                                       │   │    │
│  │  │  if next_token == eos_token_id:                      │   │    │
│  │  │      is_done[batch_idx] = True                       │   │    │
│  │  │                                                       │   │    │
│  │  │  if all(is_done):                                    │   │    │
│  │  │      break  # Выход из цикла                         │   │    │
│  │  └─────────────────────────────────────────────────────┘   │    │
│  │                          ▼                                  │    │
│  │  Yield: (tokens, lengths) для текущего шага генерации      │    │
│  │                                                              │    │
│  └────────────────────────────────────────────────────────────┘    │
│                                                                      │
│  Выход: Generator[Tuple[Tensor, Tensor]]                            │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 6: ИЗВЛЕЧЕНИЕ КОДА                           │
│                                                                      │
│  Файл: codegeex/__init__.py:57-62                                   │
│                                                                      │
│  1. Получить финальные токены из генератора                         │
│  2. Удалить токены промта:                                           │
│     generated_tokens = all_tokens[n_token_prompt:]                  │
│  3. Декодировать в текст:                                            │
│     code = tokenizer.decode_code(generated_tokens)                  │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 7: ПОСТОБРАБОТКА КОДА                        │
│                                                                      │
│  Файл: codegeex/benchmark/utils.py:151-191                          │
│  Функция: cleanup_code()                                             │
│                                                                      │
│  Язык-специфичная очистка:                                           │
│                                                                      │
│  Python:                                                             │
│    - Обнаружение нового определения функции/класса                  │
│    - Проверка изменения уровня отступа                              │
│    - Удаление кода после "\ndef ", "\nclass ", "\nif __name__"     │
│                                                                      │
│  Java/C++/Go/JavaScript:                                             │
│    - Подсчет открывающих/закрывающих скобок                         │
│    - Обрезка на балансе скобок                                       │
│    - Удаление функций main() (если не часть решения)                │
│                                                                      │
│  Общие правила:                                                      │
│    - Удаление незавершенных строк                                    │
│    - Удаление комментариев после кода                                │
│    - Обрезка пробелов                                                │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                         ВЫХОДНЫЕ ДАННЫЕ                              │
│                                                                      │
│  Формат зависит от контекста использования:                         │
│                                                                      │
│  Интерактивный режим / Web UI:                                       │
│    → Строка с сгенерированным кодом                                  │
│                                                                      │
│  Бенчмарк:                                                           │
│    {                                                                 │
│      "task_id": "Python/0",                                          │
│      "prompt": "<исходный промт>",                                   │
│      "generation": "<очищенный код>",                                │
│      "scores": -12.456,  // log probability                          │
│      "finish": 1,  // 0=incomplete, 1=early_stop, 2=eos             │
│      "output": [token_ids...]                                        │
│    }                                                                 │
└─────────────────────────────────────────────────────────────────────┘
```

### Детали реализации

#### Параметры сэмплирования

**Temperature (температура)**
- **Значение:** 0.0 - 1.0
- **Эффект:** Контролирует случайность генерации
  - `temperature = 0.2` → более детерминированный, консервативный код
  - `temperature = 0.8` → более креативный, разнообразный код
- **Формула:** `logits = logits / temperature`
- **Использование:** Низкая температура для production кода, высокая для исследования вариантов

**Top-k**
- **Значение:** 0 - 40 (обычно)
- **Эффект:** Оставляет только k токенов с наивысшими логитами
  - `top_k = 0` → отключено (все токены доступны)
  - `top_k = 40` → выбор только из 40 наиболее вероятных токенов
- **Применение:** Перед top-p фильтрацией

**Top-p (nucleus sampling)**
- **Значение:** 0.0 - 1.0
- **Эффект:** Динамический выбор минимального набора токенов с суммарной вероятностью >= p
  - `top_p = 0.95` → выбор из токенов, покрывающих 95% вероятностной массы
  - `top_p = 1.0` → все токены после top-k
- **Преимущество:** Адаптируется к распределению (больше токенов при равномерном распределении, меньше при острых пиках)

#### KV Cache оптимизация

**Без кэша (Recompute):**
```
Шаг 1: Forward([1, 2, 3, 4])       → token 5
Шаг 2: Forward([1, 2, 3, 4, 5])    → token 6
Шаг 3: Forward([1, 2, 3, 4, 5, 6]) → token 7
...
Сложность: O(n²) для генерации n токенов
```

**С KV Cache:**
```
Шаг 1: Forward([1, 2, 3, 4])       → token 5, cache_1
Шаг 2: Forward([5], cache_1)       → token 6, cache_2
Шаг 3: Forward([6], cache_2)       → token 7, cache_3
...
Сложность: O(n) для генерации n токенов
```

**Реализация:**
- `layer_past`: Кэш ключей и значений для каждого слоя внимания
- `get_key_value=True`: Возвращает обновленный кэш
- Размер кэша: `[batch, 2, num_heads, seq_len, head_dim]`

### Используемые промты

1. **Language Tags** (из PROMPTS_DOCUMENTATION.md, раздел 1)
   - Добавляются автоматически при указании языка
   - Пример: `"# language: Python\n"` + user_prompt

2. **Без явных system prompts**
   - Модель обучена на структуре кода как промте
   - Комментарии в коде служат инструкциями

### Точки интеграции

**Входные данные:**
- Пользовательский промт (строка)
- Опциональный язык программирования
- Параметры генерации (temperature, top_k, top_p, длина)

**Выходные данные:**
- Сгенерированный код (строка)
- Метаданные (для бенчмарков): scores, finish status, raw tokens

**Интеграция с другими пайплайнами:**
- → **Web UI Pipeline**: предоставляет генерацию по запросу
- → **Benchmark Evaluation Pipeline**: генерирует код для тестирования
- → **Code Translation Pipeline**: использует ту же базовую генерацию

### Оптимизации

1. **Квантизация модели** (8-bit)
   - Файл: `deployment/server_gradio.py:98-99`
   - Функция: `quantize(model, weight_bit_width=8)`
   - Эффект: Снижение использования памяти в 2 раза с минимальной потерей качества

2. **Distributed Generation**
   - ZeroMQ для распределения задач между GPU
   - Параллельная генерация множества сэмплов
   - Динамическая балансировка нагрузки

3. **Early Stopping**
   - Файл: `codegeex/benchmark/utils.py:115-149`
   - Функция: `is_code_generation_finished()`
   - Критерии остановки:
     - Обнаружена новая функция/класс
     - Изменился уровень отступа (Python)
     - Баланс скобок достигнут (C++/Java)

---

## 2. Пайплайн перевода кода

### Описание
Специализированный пайплайн для кроссязыкового перевода кода. Принимает код на одном языке программирования и генерирует эквивалентный код на другом языке, сохраняя логику и функциональность.

### Точки входа

1. **Распределенный перевод для бенчмарков**
   - **Файл:** `codegeex/benchmark/humaneval-x/translate_humaneval_x.py`
   - **Главная функция:** `main()` (строка 228)
   - **Сервер:** `server()` (строка 274) - распределение задач
   - **Воркер:** `run_generation_distributed()` - из `codegeex/megatron/inference.py`

### Схема потока данных

```
┌─────────────────────────────────────────────────────────────────────┐
│                     ИСХОДНЫЕ ДАННЫЕ                                  │
│                                                                      │
│  Source Dataset: humaneval_python.jsonl.gz                           │
│  Target Dataset: humaneval_go.jsonl.gz                               │
│                                                                      │
│  Каждая задача содержит:                                             │
│    - task_id: "HumanEval/0"                                          │
│    - prompt: объявление функции                                      │
│    - declaration: сигнатура функции                                  │
│    - canonical_solution: реализация                                  │
│    - test: тестовые случаи                                           │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 1: ЗАГРУЗКА ДАТАСЕТА ПЕРЕВОДА                │
│                                                                      │
│  Файл: codegeex/benchmark/utils.py:69-99                            │
│  Функция: read_translation_dataset()                                 │
│                                                                      │
│  Процесс:                                                            │
│    1. Загрузить source dataset                                       │
│       dataset_src = stream_jsonl(data_file_src)                      │
│                                                                      │
│    2. Загрузить target dataset                                       │
│       dataset_tgt = stream_jsonl(data_file_tgt)                      │
│                                                                      │
│    3. Извлечь названия языков                                        │
│       lang_src = dataset_src[0]["language"]  # "Python"             │
│       lang_tgt = dataset_tgt[0]["language"]  # "Go"                 │
│                                                                      │
│    4. Сопоставить задачи по task_id                                  │
│       {task_id: (src_task, tgt_task)}                                │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 2: ФОРМИРОВАНИЕ ПРОМТА ПЕРЕВОДА              │
│                                                                      │
│  Файл: codegeex/benchmark/utils.py:80-95                            │
│                                                                      │
│  Шаблон промта:                                                      │
│  ┌──────────────────────────────────────────────────────────────┐  │
│  │ code translation                                              │  │
│  │ Python:                                                       │  │
│  │ from typing import List                                       │  │
│  │                                                               │  │
│  │ def has_close_elements(numbers: List[float],                  │  │
│  │                        threshold: float) -> bool:             │  │
│  │     """ Check if in given list of numbers... """              │  │
│  │     for idx, elem in enumerate(numbers):                      │  │
│  │         for idx2, elem2 in enumerate(numbers):                │  │
│  │             if idx != idx2:                                   │  │
│  │                 distance = abs(elem - elem2)                  │  │
│  │                 if distance < threshold:                      │  │
│  │                     return True                               │  │
│  │     return False                                              │  │
│  │                                                               │  │
│  │ Go:                                                           │  │
│  │ import "math"                                                 │  │
│  │                                                               │  │
│  │ func HasCloseElements(numbers []float64,                      │  │
│  │                       threshold float64) bool {               │  │
│  └──────────────────────────────────────────────────────────────┘  │
│                                                                      │
│  Компоненты:                                                         │
│    1. Заголовок: "code translation"                                 │
│    2. Исходный язык + двоеточие: "Python:"                          │
│    3. Полный исходный код:                                           │
│       - declaration (сигнатура)                                      │
│       - canonical_solution (реализация)                              │
│    4. Целевой язык + двоеточие: "Go:"                               │
│    5. Только declaration целевого языка                             │
│       (модель должна сгенерировать тело функции)                    │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 3: АРХИТЕКТУРА СЕРВЕР-ВОРКЕР                 │
│                                                                      │
│  ┌──────────────────┐                   ┌──────────────────┐       │
│  │     СЕРВЕР       │                   │    ВОРКЕР 1      │       │
│  │  (Координатор)   │◄─────ZeroMQ──────►│   (GPU 0)        │       │
│  │                  │                   └──────────────────┘       │
│  │  - Хранит очередь│                                              │
│  │    задач          │                   ┌──────────────────┐       │
│  │  - Распределяет  │◄─────ZeroMQ──────►│    ВОРКЕР 2      │       │
│  │    работу         │                   │   (GPU 1)        │       │
│  │  - Отслеживает   │                   └──────────────────┘       │
│  │    прогресс       │                                              │
│  │                  │                   ┌──────────────────┐       │
│  │  TCP Port: 5555  │◄─────ZeroMQ──────►│    ВОРКЕР N      │       │
│  │  Socket: REP     │                   │   (GPU N-1)      │       │
│  └──────────────────┘                   └──────────────────┘       │
│                                                                      │
│  Файл: translate_humaneval_x.py:274-421                             │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 4: ПРОТОКОЛ ВЗАИМОДЕЙСТВИЯ                   │
│                                                                      │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │  ВОРКЕР → СЕРВЕР: Запрос задачи                           │    │
│  │  {                                                          │    │
│  │    "rank": 0,                                              │    │
│  │    "action": "pull"                                        │    │
│  │  }                                                          │    │
│  └────────────────────────────────────────────────────────────┘    │
│                             ▼                                       │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │  СЕРВЕР → ВОРКЕР: Назначение задачи                       │    │
│  │  {                                                          │    │
│  │    "task_id": {                                            │    │
│  │      "task_id": "Python-Go/HumanEval/0",                   │    │
│  │      "prompt": "code translation\nPython:\n...",           │    │
│  │      "temperature": 0.2,                                   │    │
│  │      "topp": 0.95,                                         │    │
│  │      "micro_batch_size": 1                                 │    │
│  │    }                                                        │    │
│  │  }                                                          │    │
│  │                                                             │    │
│  │  ИЛИ (если задачи закончились):                            │    │
│  │  {                                                          │    │
│  │    "task_id": None  // Сигнал завершения                   │    │
│  │  }                                                          │    │
│  └────────────────────────────────────────────────────────────┘    │
│                             ▼                                       │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │  ВОРКЕР: Генерация кода                                    │    │
│  │  (Использует стандартный пайплайн генерации)               │    │
│  └────────────────────────────────────────────────────────────┘    │
│                             ▼                                       │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │  ВОРКЕР → СЕРВЕР: Отчет об успехе                         │    │
│  │  {                                                          │    │
│  │    "rank": 0,                                              │    │
│  │    "action": "success",                                    │    │
│  │    "task_id": "Python-Go/HumanEval/0"                      │    │
│  │  }                                                          │    │
│  │                                                             │    │
│  │  ИЛИ (при ошибке):                                          │    │
│  │  {                                                          │    │
│  │    "rank": 0,                                              │    │
│  │    "action": "fail",                                       │    │
│  │    "task_id": {...}  // Возвращает задачу в очередь        │    │
│  │  }                                                          │    │
│  └────────────────────────────────────────────────────────────┘    │
│                             ▼                                       │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │  СЕРВЕР → ВОРКЕР: Подтверждение                           │    │
│  │  {                                                          │    │
│  │    "pong": 1                                               │    │
│  │  }                                                          │    │
│  └────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 5: ГЕНЕРАЦИЯ ПЕРЕВОДА                        │
│                                                                      │
│  Файл: codegeex/megatron/inference.py:35-245                        │
│  Функция: run_generation_distributed()                               │
│                                                                      │
│  Процесс воркера:                                                    │
│                                                                      │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │  Цикл обработки задач                                      │    │
│  │                                                             │    │
│  │  1. Запросить задачу у сервера (pull)                      │    │
│  │                                                             │    │
│  │  2. Если task_id == None: завершить работу                 │    │
│  │                                                             │    │
│  │  3. Извлечь промт перевода из задачи                       │    │
│  │                                                             │    │
│  │  4. Токенизировать промт                                    │    │
│  │                                                             │    │
│  │  5. Вызвать get_token_stream()                              │    │
│  │     → Использует ТОТ ЖЕ код генерации, что и для           │    │
│  │       обычной генерации кода                                │    │
│  │     → Разница только в структуре промта                     │    │
│  │                                                             │    │
│  │  6. Получить сгенерированные токены                         │    │
│  │                                                             │    │
│  │  7. Декодировать токены в текст                             │    │
│  │                                                             │    │
│  │  8. Очистить код (cleanup_code)                             │    │
│  │     - Удалить лишний код после функции                      │    │
│  │     - Проверить синтаксис целевого языка                    │    │
│  │                                                             │    │
│  │  9. Записать результат в файл                               │    │
│  │     python-to-go_finished_rank0.jsonl                       │    │
│  │                                                             │    │
│  │ 10. Отправить success/fail серверу                          │    │
│  │                                                             │    │
│  │ 11. Повторить                                               │    │
│  └────────────────────────────────────────────────────────────┘    │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 6: СПЕЦИФИЧНАЯ ПОСТОБРАБОТКА                 │
│                                                                      │
│  Дополнительные проверки для перевода:                              │
│                                                                      │
│  1. Удаление "утекшего" синтаксиса исходного языка                  │
│     - Проверка на смешение Python и Go синтаксиса                   │
│     - Удаление импортов исходного языка                             │
│                                                                      │
│  2. Валидация синтаксиса целевого языка                             │
│     - Проверка соответствия naming conventions                      │
│     - Проверка структуры (скобки, отступы)                          │
│                                                                      │
│  3. Сохранение дополнительных метрик                                │
│     - Log probability оригинального и переведенного кода            │
│     - Длина генерации                                                │
│     - Статус завершения (EOS, early stop, incomplete)               │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                         ВЫХОДНЫЕ ДАННЫЕ                              │
│                                                                      │
│  Формат выходного файла:                                             │
│  {lang_src}-to-{lang_tgt}_finished_rank{rank}.jsonl                 │
│                                                                      │
│  Каждая строка:                                                      │
│  {                                                                   │
│    "task_id": "Python-Go/HumanEval/0",                              │
│    "prompt": "code translation\nPython:\n<src_code>\nGo:\n<decl>",  │
│    "generation": "<translated_go_code>",                             │
│    "scores": -15.234,  // Log probability                            │
│    "finish": 1,  // 0=incomplete, 1=early_stop, 2=eos               │
│    "output": [token_ids...]                                          │
│  }                                                                   │
│                                                                      │
│  Незавершенные генерации:                                            │
│  {lang_src}-to-{lang_tgt}_unfinished_rank{rank}.jsonl               │
│                                                                      │
│  Статистика сервера (консоль):                                       │
│    Progress: 125/164 (76.2%)                                         │
│    Speed: 12.5 samples/sec                                           │
│    Estimated remaining: 3.1 minutes                                  │
└─────────────────────────────────────────────────────────────────────┘
```

### Детали реализации

#### Поддерживаемые направления перевода

**Основные языки:** Python, Java, C++, JavaScript, Go, Rust

**Всего 30 направлений:**
```
Python → {Java, C++, JavaScript, Go, Rust}     (5 направлений)
Java → {Python, C++, JavaScript, Go, Rust}     (5 направлений)
C++ → {Python, Java, JavaScript, Go, Rust}     (5 направлений)
JavaScript → {Python, Java, C++, Go, Rust}     (5 направлений)
Go → {Python, Java, C++, JavaScript, Rust}     (5 направлений)
Rust → {Python, Java, C++, JavaScript, Go}     (5 направлений)
```

#### Структура промта перевода

**Критически важные элементы:**

1. **Заголовок "code translation"**
   - Точная строка, модель обучена распознавать этот маркер
   - Без этого модель будет генерировать код, а не переводить

2. **Двоеточие после названия языка**
   - "Python:" а не "Python"
   - Указывает модели на начало кодового блока

3. **Полный исходный код**
   - И declaration, и solution
   - Модели нужен полный контекст для понимания логики

4. **Только declaration целевого языка**
   - Без реализации
   - Модель завершает реализацию на основе исходного кода

#### Балансировка нагрузки

**Динамическое распределение:**
```
Сервер:
  remaining_entries = [task1, task2, ..., taskN]

Воркер запрашивает задачу:
  task = remaining_entries.pop()

Воркер сообщает о провале:
  remaining_entries.append(task)  // Возврат в очередь
```

**Преимущества:**
- Быстрые GPU обрабатывают больше задач
- Автоматическая повторная попытка при сбоях
- Нет простоя (GPU всегда заняты, пока есть задачи)

#### Оптимизация для перевода

**1. Температура для перевода:**
- Обычно ниже, чем для генерации: `temperature = 0.2`
- Перевод требует большей точности, меньшей креативности

**2. Samples per problem:**
- Обычно генерируется 1-5 переводов на задачу
- Выбирается лучший на основе pass@k метрики

**3. Batch размер:**
- `micro_batch_size = 1` для перевода
- Каждая задача уникальна, батчинг неэффективен

### Используемые промты

**Из PROMPTS_DOCUMENTATION.md, раздел 2: "Промты для перевода кода"**

Пример промта:
```
code translation
Python:
from typing import List

def has_close_elements(numbers: List[float], threshold: float) -> bool:
    """ Check if in given list of numbers, are any two numbers closer to each other than
    given threshold. """
    for idx, elem in enumerate(numbers):
        for idx2, elem2 in enumerate(numbers):
            if idx != idx2:
                distance = abs(elem - elem2)
                if distance < threshold:
                    return True
    return False

Go:
import "math"

func HasCloseElements(numbers []float64, threshold float64) bool {
```

### Точки интеграции

**Входные данные:**
- Source dataset (JSONL с задачами на исходном языке)
- Target dataset (JSONL с объявлениями на целевом языке)
- Языковая пара (src_lang, tgt_lang)

**Выходные данные:**
- Переведенный код (строка)
- Метрики: scores, finish status
- Отдельные файлы для completed и uncompleted переводов

**Интеграция с другими пайплайнами:**
- ← **Code Generation Pipeline**: использует ту же базовую генерацию
- → **Benchmark Evaluation Pipeline**: переведенный код оценивается на тестах целевого языка

### Отличия от обычной генерации

| Аспект | Обычная генерация | Перевод кода |
|--------|-------------------|--------------|
| **Промт** | Описание задачи | code translation + исходный код |
| **Контекст** | Только задача | Полная реализация на исходном языке |
| **Цель** | Создать новый код | Сохранить логику, изменить синтаксис |
| **Температура** | 0.2 - 0.8 | 0.1 - 0.3 (более детерминированно) |
| **Оценка** | Функциональная корректность | Корректность + эквивалентность исходному |

---

## 3. Пайплайн оценки бенчмарков

### Описание
Пайплайн для автоматической оценки функциональной корректности сгенерированного кода путем выполнения тестовых случаев. Вычисляет метрики pass@k для измерения качества модели.

### Точки входа

1. **Оценка HumanEval-X**
   - **Файл:** `codegeex/benchmark/evaluate_humaneval_x.py`
   - **Главная функция:** `evaluate_functional_correctness()` (строка 99)
   - **Функция выполнения:** `check_correctness()` из `codegeex/benchmark/execution.py` (строка 44)

### Схема потока данных

```
┌─────────────────────────────────────────────────────────────────────┐
│                         ВХОДНЫЕ ДАННЫЕ                               │
│                                                                      │
│  1. Problem File: humaneval_python.jsonl.gz                          │
│     {                                                                │
│       "task_id": "HumanEval/0",                                      │
│       "prompt": "def has_close_elements(...):",                      │
│       "test": "def check():\n    assert ...",                        │
│       "canonical_solution": "    for ...\n    return ...",           │
│       "entry_point": "has_close_elements"                            │
│     }                                                                │
│                                                                      │
│  2. Generated Samples: samples_output.jsonl                          │
│     {                                                                │
│       "task_id": "HumanEval/0",                                      │
│       "generation": "    for i in range(len(numbers)):\n...",        │
│       "prompt": "def has_close_elements(...):",                      │
│       "scores": -12.34                                               │
│     }                                                                │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 1: ЗАГРУЗКА И ГРУППИРОВКА                    │
│                                                                      │
│  Файл: evaluate_humaneval_x.py:99-232                                │
│  Функция: evaluate_functional_correctness()                          │
│                                                                      │
│  1. Загрузить ground truth проблемы:                                 │
│     problems = {task_id: problem_data}                               │
│                                                                      │
│  2. Загрузить сгенерированные решения:                               │
│     samples = [sample1, sample2, ..., sampleN]                       │
│                                                                      │
│  3. Группировка по task_id:                                          │
│     task_samples = defaultdict(list)                                 │
│     for sample in samples:                                           │
│         task_samples[sample["task_id"]].append(sample)               │
│                                                                      │
│  Результат: {task_id: [sample1, sample2, ..., sampleK]}             │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 2: ФОРМИРОВАНИЕ ТЕСТОВОГО КОДА               │
│                                                                      │
│  Файл: evaluate_humaneval_x.py:27-82                                 │
│  Функция: process_humaneval_test()                                   │
│                                                                      │
│  Для каждой (sample, problem) пары:                                  │
│                                                                      │
│  ┌──────────────────────────────────────────────────────────────┐  │
│  │  PYTHON                                                       │  │
│  │                                                               │  │
│  │  test_setup (imports) +                                       │  │
│  │  "\n" +                                                       │  │
│  │  problem["prompt"] +  // def has_close_elements(...):         │  │
│  │  "\n" +                                                       │  │
│  │  sample["generation"] +  // implementation                    │  │
│  │  "\n" +                                                       │  │
│  │  problem["test"] +  // test cases                             │  │
│  │  "\n\ncheck()"                                                │  │
│  └──────────────────────────────────────────────────────────────┘  │
│                                                                      │
│  ┌──────────────────────────────────────────────────────────────┐  │
│  │  C++                                                          │  │
│  │                                                               │  │
│  │  test_setup (includes) +                                      │  │
│  │  "\n" +                                                       │  │
│  │  problem["prompt"] +  // function signature                   │  │
│  │  sample["generation"] +  // function body                     │  │
│  │  "}\n" +  // close function                                   │  │
│  │  problem["test"]  // main with assertions                     │  │
│  └──────────────────────────────────────────────────────────────┘  │
│                                                                      │
│  ┌──────────────────────────────────────────────────────────────┐  │
│  │  GO                                                           │  │
│  │                                                               │  │
│  │  "package main\n" +                                           │  │
│  │  test_setup (imports) +                                       │  │
│  │  problem["prompt"] +                                          │  │
│  │  sample["generation"] +                                       │  │
│  │  "}\n" +                                                       │  │
│  │  problem["test"]                                              │  │
│  └──────────────────────────────────────────────────────────────┘  │
│                                                                      │
│  Аналогично для Java, JavaScript                                    │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 3: ПАРАЛЛЕЛЬНОЕ ВЫПОЛНЕНИЕ                   │
│                                                                      │
│  Файл: evaluate_humaneval_x.py:136-189                               │
│                                                                      │
│  ThreadPoolExecutor с n_workers потоками:                            │
│                                                                      │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐           │
│  │ Thread 1 │  │ Thread 2 │  │ Thread 3 │  │ Thread N │           │
│  │          │  │          │  │          │  │          │           │
│  │  Task 1  │  │  Task 5  │  │  Task 9  │  │  Task M  │           │
│  │  Task 2  │  │  Task 6  │  │  Task 10 │  │          │           │
│  │  Task 3  │  │  Task 7  │  │  Task 11 │  │          │           │
│  │  Task 4  │  │  Task 8  │  │  Task 12 │  │          │           │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘           │
│       │             │             │             │                  │
│       └─────────────┴─────────────┴─────────────┘                  │
│                         │                                           │
│                         ▼                                           │
│               Executor Pool Queue                                   │
│         [task1, task2, ..., taskN]                                  │
│                                                                      │
│  Каждый поток:                                                       │
│    1. Извлекает задачу (task_id, sample, lang, timeout)            │
│    2. Вызывает check_correctness(...)                               │
│    3. Возвращает результат: (task_id, passed/failed)                │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 4: ВЫПОЛНЕНИЕ ПО ЯЗЫКАМ                      │
│                                                                      │
│  Файл: codegeex/benchmark/execution.py:44-386                       │
│  Функция: check_correctness()                                        │
│                                                                      │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │  MULTIPROCESSING SAFETY WRAPPER                            │    │
│  │                                                             │    │
│  │  manager = multiprocessing.Manager()                       │    │
│  │  result = manager.list()                                   │    │
│  │                                                             │    │
│  │  p = multiprocessing.Process(                              │    │
│  │      target=unsafe_execute,                                │    │
│  │      args=(tmp_dir,)                                       │    │
│  │  )                                                          │    │
│  │                                                             │    │
│  │  p.start()                                                  │    │
│  │  p.join(timeout=timeout + 1)                               │    │
│  │                                                             │    │
│  │  if p.is_alive():                                          │    │
│  │      p.kill()  // Kill if timeout                          │    │
│  │      result.append("timed out")                            │    │
│  └────────────────────────────────────────────────────────────┘    │
│                             │                                       │
│                             ▼                                       │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │  unsafe_execute() - Выполнение специфично для языка       │    │
│  │                                                             │    │
│  │  ┌───────────────────────────────────────────────────┐    │    │
│  │  │  PYTHON (lines 59-97)                             │    │    │
│  │  │                                                     │    │    │
│  │  │  1. Создать temp директорию                        │    │    │
│  │  │  2. Применить reliability_guard():                 │    │    │
│  │  │     - Отключить os.system, subprocess              │    │    │
│  │  │     - Отключить os.remove, shutil.rmtree           │    │    │
│  │  │     - Ограничить память (optional)                 │    │    │
│  │  │  3. exec(test_code) в изолированной среде          │    │    │
│  │  │  4. Поймать исключения:                            │    │    │
│  │  │     - TimeoutException → "timed out"               │    │    │
│  │  │     - AssertionError → "failed: assertion"         │    │    │
│  │  │     - Exception → "failed: {error}"                │    │    │
│  │  │  5. Вернуть "passed" если нет ошибок               │    │    │
│  │  └───────────────────────────────────────────────────┘    │    │
│  │                                                             │    │
│  │  ┌───────────────────────────────────────────────────┐    │    │
│  │  │  GO (lines 99-145)                                │    │    │
│  │  │                                                     │    │    │
│  │  │  1. Создать temp/{task_id}-{random}                │    │    │
│  │  │  2. Записать main_test.go                          │    │    │
│  │  │  3. subprocess.run([                               │    │    │
│  │  │       "go", "test",                                 │    │    │
│  │  │       f"-timeout={timeout}s"                        │    │    │
│  │  │     ])                                              │    │    │
│  │  │  4. Проверить returncode                           │    │    │
│  │  │  5. Если 0: "passed", иначе: "failed"              │    │    │
│  │  └───────────────────────────────────────────────────┘    │    │
│  │                                                             │    │
│  │  ┌───────────────────────────────────────────────────┐    │    │
│  │  │  JAVASCRIPT (lines 146-184)                       │    │    │
│  │  │                                                     │    │    │
│  │  │  1. Записать test.js                               │    │    │
│  │  │  2. subprocess.run(["node", "test.js"])            │    │    │
│  │  │  3. Проверить stdout/stderr                        │    │    │
│  │  └───────────────────────────────────────────────────┘    │    │
│  │                                                             │    │
│  │  ┌───────────────────────────────────────────────────┐    │    │
│  │  │  C++ (lines 185-242)                              │    │    │
│  │  │                                                     │    │    │
│  │  │  1. Записать test.cpp                              │    │    │
│  │  │  2. Компиляция:                                    │    │    │
│  │  │     g++ -std=c++11 test.cpp -o executable          │    │    │
│  │  │  3. Если компиляция провалена: "failed"            │    │    │
│  │  │  4. Выполнить: ./executable                        │    │    │
│  │  │  5. Проверить returncode                           │    │    │
│  │  └───────────────────────────────────────────────────┘    │    │
│  │                                                             │    │
│  │  ┌───────────────────────────────────────────────────┐    │    │
│  │  │  JAVA (lines 309-361)                             │    │    │
│  │  │                                                     │    │    │
│  │  │  1. Записать Main.java                             │    │    │
│  │  │  2. Компиляция: javac Main.java                    │    │    │
│  │  │  3. Выполнить: java -cp {tmp_dir} Main            │    │    │
│  │  │  4. Проверить результат                            │    │    │
│  │  └───────────────────────────────────────────────────┘    │    │
│  │                                                             │    │
│  └────────────────────────────────────────────────────────────┘    │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 5: АГРЕГАЦИЯ РЕЗУЛЬТАТОВ                     │
│                                                                      │
│  Файл: evaluate_humaneval_x.py:190-200                               │
│                                                                      │
│  Собрать результаты из futures:                                      │
│                                                                      │
│  results = {}  # {task_id: [(completion_id, result), ...]}          │
│                                                                      │
│  for future in as_completed(futures):                                │
│      result = future.result()                                        │
│      task_id = result["task_id"]                                     │
│      completion_id = result["completion_id"]                         │
│      passed = (result["result"] == "passed")                         │
│                                                                      │
│      results[task_id].append((completion_id, passed))                │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 6: ВЫЧИСЛЕНИЕ МЕТРИК                         │
│                                                                      │
│  Файл: evaluate_humaneval_x.py:201-216                               │
│  Функция: estimate_pass_at_k()                                       │
│                                                                      │
│  Для каждой задачи:                                                  │
│    total_samples = количество сгенерированных решений               │
│    correct_samples = количество passed решений                      │
│                                                                      │
│  Вычислить pass@k для k ∈ {1, 10, 100}:                            │
│                                                                      │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │  pass@k = E[1 - C(n-c, k) / C(n, k)]                       │    │
│  │                                                             │    │
│  │  где:                                                       │    │
│  │    n = total_samples                                        │    │
│  │    c = correct_samples                                      │    │
│  │    k = количество попыток                                   │    │
│  │    C(n, k) = биномиальный коэффициент                       │    │
│  │                                                             │    │
│  │  Интерпретация:                                             │    │
│  │    Вероятность получить хотя бы одно правильное решение    │    │
│  │    из k случайно выбранных генераций                        │    │
│  └────────────────────────────────────────────────────────────┘    │
│                                                                      │
│  Пример:                                                             │
│    Задача: HumanEval/0                                               │
│    Сгенерировано: 100 решений                                        │
│    Прошло тесты: 32 решения                                          │
│                                                                      │
│    pass@1 = 32/100 = 0.32   (32% шанс с 1 попытки)                  │
│    pass@10 ≈ 0.97            (97% шанс с 10 попыток)                │
│    pass@100 = 1.00           (100% шанс с 100 попыток)              │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                         ВЫХОДНЫЕ ДАННЫЕ                              │
│                                                                      │
│  1. Консольный вывод:                                                │
│     pass@1: 0.456                                                    │
│     pass@10: 0.678                                                   │
│     pass@100: 0.812                                                  │
│     Total: 16400                                                     │
│     Correct: 7482                                                    │
│                                                                      │
│  2. Результаты файл: {input_file}_results.jsonl                     │
│     Каждая строка:                                                   │
│     {                                                                │
│       "task_id": "HumanEval/0",                                      │
│       "completion_id": 0,                                            │
│       "test_code": "<полный тестовый код>",                          │
│       "prompt": "def has_close_elements(...):",                      │
│       "generation": "<сгенерированный код>",                         │
│       "result": "passed" или "failed: <reason>",                     │
│       "passed": true/false,                                          │
│       "finish": 1,                                                   │
│       "file": "samples_rank0.jsonl",                                 │
│       "output": [token_ids...]                                       │
│     }                                                                │
└─────────────────────────────────────────────────────────────────────┘
```

### Детали реализации

#### Безопасность выполнения кода

**reliability_guard() (execution.py:477-550):**

Песочница для Python кода:
```python
def reliability_guard():
    # Отключить опасные функции
    __builtins__['exec'] = None
    __builtins__['eval'] = None

    # Заблокировать системные вызовы
    os.system = lambda *args: None
    subprocess.Popen = None
    subprocess.call = None

    # Заблокировать файловые операции
    os.remove = None
    os.rmdir = None
    shutil.rmtree = None

    # Ограничить память (optional)
    import resource
    resource.setrlimit(resource.RLIMIT_AS, (memory_limit, memory_limit))
```

#### Таймауты по языкам

| Язык | Таймаут | Причина |
|------|---------|---------|
| Python | 3s | Интерпретируемый, быстрый старт |
| JavaScript | 3s | V8 JIT, быстрый |
| Go | 10s | Требуется компиляция |
| C++ | 10s | Компиляция + выполнение |
| Java | 10s | Компиляция + JVM старт |

#### Pass@k метрика

**Несмещенная оценка:**

```
pass@k = 1 - C(n-c, k) / C(n, k)

где:
  n = общее количество генераций
  c = количество корректных генераций
  k = количество попыток

Примеры:
  n=100, c=30, k=1  → pass@1 = 30%
  n=100, c=30, k=10 → pass@10 ≈ 97%
```

**Интерпретация:**
- pass@1: Вероятность успеха с первой попытки (жесткая метрика)
- pass@10: Вероятность успеха за 10 попыток (реалистичная для IDE)
- pass@100: Вероятность успеха за 100 попыток (верхняя граница модели)

### Используемые промты

**Нет специфичных промтов** - пайплайн только выполняет и оценивает уже сгенерированный код

Однако использует:
- test_setup константы (IMPORT_HELPER из PROMPTS_DOCUMENTATION.md, раздел 5)
- Тестовые случаи из датасета

### Точки интеграции

**Входные данные:**
- Файл с проблемами (ground truth)
- Файл со сгенерированными решениями

**Выходные данные:**
- Метрики pass@k
- Детальные результаты выполнения каждого теста

**Интеграция с другими пайплайнами:**
- ← **Code Generation Pipeline**: получает сгенерированный код
- ← **Code Translation Pipeline**: получает переведенный код
- → Используется для измерения качества модели

---

## 4. Пайплайн веб-интерфейса

### Описание
Веб-интерфейс на базе Gradio для интерактивной генерации кода. Позволяет пользователям вводить промты, выбирать параметры генерации и получать результаты в реальном времени.

### Точки входа

1. **Gradio сервер**
   - **Файл:** `deployment/server_gradio.py`
   - **Главная функция:** `main()` (строка 85)
   - **Функция генерации:** `predict()` (строка 108)
   - **URL:** `http://localhost:6007`

### Схема потока данных

```
┌─────────────────────────────────────────────────────────────────────┐
│                         БРАУЗЕР ПОЛЬЗОВАТЕЛЯ                         │
│                                                                      │
│  ┌──────────────────────────────────────────────────────────────┐  │
│  │                     GRADIO INTERFACE                          │  │
│  │                                                               │  │
│  │  Inputs:                                                      │  │
│  │    ┌────────────────────────────────────────────────┐        │  │
│  │    │  Prompt (Textbox, 13 lines)                    │        │  │
│  │    │  "Write a function to calculate factorial"     │        │  │
│  │    └────────────────────────────────────────────────┘        │  │
│  │                                                               │  │
│  │    Language: ( ) Python (•) Java ( ) C++ ( ) Go ...          │  │
│  │                                                               │  │
│  │    ─────────────── Parameters ────────────────               │  │
│  │    Seed:          [======•=============] 42                  │  │
│  │    Out Length:    [=============•======] 256                 │  │
│  │    Temperature:   [====•===============] 0.2                 │  │
│  │    Top-k:         [==========•=========] 40                  │  │
│  │    Top-p:         [===============•====] 0.95                │  │
│  │                                                               │  │
│  │    [Generate]  [Clear]                                        │  │
│  │                                                               │  │
│  │    Or select an example:                                      │  │
│  │    [Example 1: Python Sum] [Example 2: C++ Sort] ...         │  │
│  │                                                               │  │
│  │  Output:                                                      │  │
│  │    ┌────────────────────────────────────────────────┐        │  │
│  │    │ def factorial(n):                              │        │  │
│  │    │     if n <= 1:                                 │        │  │
│  │    │         return 1                               │        │  │
│  │    │     return n * factorial(n - 1)                │        │  │
│  │    └────────────────────────────────────────────────┘        │  │
│  └──────────────────────────────────────────────────────────────┘  │
└────────────────────────────┬────────────────────────────────────────┘
                             │ HTTP POST /api/predict
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    СЕРВЕР (Python Flask/Gradio)                     │
│                                                                      │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │  ШАГ 1: ИНИЦИАЛИЗАЦИЯ СЕРВЕРА                             │    │
│  │                                                             │    │
│  │  Файл: server_gradio.py:85-106                             │    │
│  │  Функция: main()                                            │    │
│  │                                                             │    │
│  │  1. Парсинг аргументов (model_config, load, etc.)          │    │
│  │                                                             │    │
│  │  2. Загрузка токенизатора:                                  │    │
│  │     tokenizer = CodeGeeXTokenizer(                          │    │
│  │         tokenizer_path,                                     │    │
│  │         mode="codegeex-13b"                                 │    │
│  │     )                                                       │    │
│  │                                                             │    │
│  │  3. Загрузка модели:                                        │    │
│  │     model = CodeGeeXModel(args)                             │    │
│  │     state_dict = torch.load(checkpoint)                     │    │
│  │     model.load_state_dict(state_dict)                       │    │
│  │     model.eval().half()                                     │    │
│  │                                                             │    │
│  │  4. Опционально: Квантизация                                │    │
│  │     model = quantize(model, weight_bit_width=8)             │    │
│  │                                                             │    │
│  │  5. Перенос на GPU:                                         │    │
│  │     model.cuda()                                            │    │
│  │                                                             │    │
│  │  6. Создание Gradio интерфейса (lines 141-193)             │    │
│  │     demo = gr.Blocks()                                      │    │
│  │     gen.click(fn=predict, inputs=..., outputs=...)          │    │
│  │                                                             │    │
│  │  7. Запуск сервера:                                         │    │
│  │     demo.launch(server_port=6007)                           │    │
│  └────────────────────────────────────────────────────────────┘    │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 2: ОБРАБОТКА ЗАПРОСА                         │
│                                                                      │
│  Файл: server_gradio.py:108-134                                      │
│  Функция: predict()                                                  │
│                                                                      │
│  Параметры функции:                                                  │
│    - prompt: str                                                     │
│    - lang: str (Python/Java/C++/...)                                │
│    - seed: int                                                       │
│    - out_seq_length: int                                             │
│    - temperature: float                                              │
│    - top_k: int                                                      │
│    - top_p: float                                                    │
│                                                                      │
│  1. Установить random seed:                                          │
│     set_random_seed(seed)                                            │
│     torch.manual_seed(seed)                                          │
│     torch.cuda.manual_seed_all(seed)                                 │
│                                                                      │
│  2. Добавить language tag:                                           │
│     if lang.lower() in LANGUAGE_TAG:                                 │
│         prompt = LANGUAGE_TAG[lang.lower()] + "\n" + prompt          │
│                                                                      │
│     Пример:                                                          │
│       Input: "def factorial(n):"                                     │
│       Output: "# language: Python\ndef factorial(n):"                │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 3: ГЕНЕРАЦИЯ КОДА                            │
│                                                                      │
│  Файл: server_gradio.py:121-131                                      │
│                                                                      │
│  generated_code = codegeex.generate(                                 │
│      model=model,                                                    │
│      tokenizer=tokenizer,                                            │
│      prompt=prompt,                                                  │
│      out_seq_length=out_seq_length,                                  │
│      seq_length=2048,  // max context                                │
│      top_k=top_k,                                                    │
│      top_p=top_p,                                                    │
│      temperature=temperature,                                        │
│      micro_batch_size=1,  // single request                          │
│      backend="megatron"                                              │
│  )                                                                   │
│                                                                      │
│  → Вызывает ТОТ ЖЕ Code Generation Pipeline                         │
│    (см. раздел 1 этого документа)                                   │
│                                                                      │
│  Процесс:                                                            │
│    1. Токенизация → 2. Forward Pass → 3. Sampling →                 │
│    4. Декодирование → 5. Возврат кода                                │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    ШАГ 4: ВОЗВРАТ РЕЗУЛЬТАТА                        │
│                                                                      │
│  Файл: server_gradio.py:133                                          │
│                                                                      │
│  return prompt + generated_code                                      │
│                                                                      │
│  Пример выхода:                                                      │
│    # language: Python                                                │
│    def factorial(n):                                                 │
│        """Calculate factorial of n"""                                │
│        if n <= 1:                                                    │
│            return 1                                                  │
│        return n * factorial(n - 1)                                   │
└────────────────────────────┬────────────────────────────────────────┘
                             │ HTTP Response (JSON)
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                         БРАУЗЕР ПОЛЬЗОВАТЕЛЯ                         │
│                                                                      │
│  Gradio отображает результат в Output Textbox                       │
│  Пользователь может:                                                 │
│    - Скопировать код                                                 │
│    - Изменить параметры и перегенерировать                          │
│    - Очистить и начать заново                                        │
│    - Выбрать другой пример                                           │
└─────────────────────────────────────────────────────────────────────┘
```

### Детали реализации

#### Gradio компоненты

**Входы:**
```python
gr.Textbox(lines=13, label="Prompt")  # Многострочный ввод
gr.Radio(choices=["Python", "Java", ...])  # Выбор языка
gr.Slider(0, 10000, value=42, label="Seed")  # Random seed
gr.Slider(1, 1024, value=128, label="Out Length")  # Длина генерации
gr.Slider(0, 1, value=0.2, label="Temperature")  # Температура
gr.Slider(0, 40, value=40, label="Top-k")
gr.Slider(0, 1, value=0.95, label="Top-p")
```

**Выходы:**
```python
gr.Textbox(lines=15, label="Output")  # Сгенерированный код
```

**Примеры:**
```python
gr.Examples(
    examples=load_examples("example_inputs.jsonl"),
    inputs=[prompt, lang, ...]
)
```

#### API endpoints (автоматически от Gradio)

**POST /api/predict:**
```json
{
  "data": [
    "def factorial(n):",  // prompt
    "Python",              // lang
    42,                    // seed
    256,                   // out_seq_length
    0.2,                   // temperature
    40,                    // top_k
    0.95                   // top_p
  ]
}
```

**Response:**
```json
{
  "data": [
    "# language: Python\ndef factorial(n):\n    if n <= 1:\n        return 1\n    return n * factorial(n - 1)"
  ],
  "duration": 1.234
}
```

#### Оптимизация для Web UI

1. **Модель всегда в памяти**
   - Загружается один раз при старте
   - Минимизирует latency для запросов

2. **Квантизация 8-bit**
   - Опциональная, через `--quantize`
   - Снижает использование VRAM: 26GB → 13GB
   - Незначительное снижение качества

3. **Single batch processing**
   - `micro_batch_size=1`
   - Каждый запрос обрабатывается отдельно
   - Оптимально для интерактивного использования

4. **Потоковая генерация (опция)**
   - Можно включить streaming
   - Отображение токенов по мере генерации
   - Улучшает perceived latency

### Используемые промты

**Из PROMPTS_DOCUMENTATION.md:**
- Раздел 1: Language Tags (автоматически добавляются)
- Раздел 3: Example Prompts (загружаются в интерфейс)

**Пример загрузки примеров:**
```python
examples = []
with open("deployment/example_inputs.jsonl") as f:
    for line in f:
        example = json.loads(line)
        examples.append([
            example["context"],  // prompt
            example.get("language", "Python"),
            example.get("seed", 42),
            # ... other params
        ])
```

### Точки интеграции

**Входные данные:**
- HTTP запросы от браузера (через Gradio)
- Параметры генерации от пользователя

**Выходные данные:**
- HTTP response с сгенерированным кодом
- Отображение в браузере

**Интеграция с другими пайплайнами:**
- → **Code Generation Pipeline**: использует напрямую для генерации
- Не интегрируется с Translation или Evaluation (пока)

**Расширяемость:**
- Можно добавить вкладку для Code Translation
- Можно добавить онлайн evaluation (запуск тестов в браузере)

---

## 5. Общая архитектура системы

### Взаимосвязь пайплайнов

```
                                ┌──────────────────┐
                                │  ПОЛЬЗОВАТЕЛЬ    │
                                └────────┬─────────┘
                                         │
                     ┌───────────────────┼───────────────────┐
                     │                   │                   │
                     ▼                   ▼                   ▼
           ┌──────────────────┐ ┌──────────────────┐ ┌────────────────┐
           │   WEB UI         │ │   CLI SCRIPT     │ │  API REQUEST   │
           │  (Gradio)        │ │  (test_inference)│ │  (ZeroMQ)      │
           └────────┬─────────┘ └────────┬─────────┘ └────────┬───────┘
                    │                    │                    │
                    └────────────────────┼────────────────────┘
                                         │
                                         ▼
                              ┌─────────────────────┐
                              │  CODE GENERATION    │
                              │     PIPELINE        │
                              │                     │
                              │  1. Tokenization    │
                              │  2. Model Forward   │
                              │  3. Sampling        │
                              │  4. Decoding        │
                              │  5. Cleanup         │
                              └──────────┬──────────┘
                                         │
                        ┌────────────────┼────────────────┐
                        │                │                │
                        ▼                ▼                ▼
              ┌──────────────┐ ┌──────────────┐ ┌──────────────┐
              │   STANDARD   │ │ TRANSLATION  │ │   TEST/      │
              │  GENERATION  │ │  (with       │ │  BENCHMARK   │
              │              │ │  code trans  │ │              │
              │              │ │  prompt)     │ │              │
              └──────┬───────┘ └──────┬───────┘ └──────┬───────┘
                     │                │                │
                     │                └────────┬───────┘
                     │                         │
                     └─────────────────────────┼───────────────┐
                                               │               │
                                               ▼               ▼
                                    ┌──────────────┐ ┌─────────────────┐
                                    │  SAVE TO     │ │   BENCHMARK     │
                                    │  FILE        │ │   EVALUATION    │
                                    │  (.jsonl)    │ │   PIPELINE      │
                                    └──────────────┘ │                 │
                                                     │  1. Load tests  │
                                                     │  2. Execute     │
                                                     │  3. Aggregate   │
                                                     │  4. Calculate   │
                                                     │     pass@k      │
                                                     └────────┬────────┘
                                                              │
                                                              ▼
                                                     ┌─────────────────┐
                                                     │   METRICS       │
                                                     │   OUTPUT        │
                                                     │                 │
                                                     │  pass@1: 0.456  │
                                                     │  pass@10: 0.678 │
                                                     │  pass@100: 0.82 │
                                                     └─────────────────┘
```

### Общие компоненты

**Все пайплайны используют:**

1. **CodeGeeXTokenizer** (`codegeex/tokenizer/`)
   - GPT2-BPE алгоритм
   - Специальные токены для кода
   - Методы: `encode_code()`, `decode_code()`

2. **CodeGeeXModel** (`codegeex/torch/codegeex_model.py`)
   - 39-layer Transformer decoder
   - 5120 hidden size, 40 attention heads
   - 13B параметров

3. **Sampling Functions** (`codegeex/torch/inference.py`)
   - `top_k_logits()`: Top-k и nucleus фильтрация
   - `sample_sequence_batch()`: Авторегрессивная генерация
   - `beam_search()`: Beam search (опционально)

4. **Utility Functions** (`codegeex/benchmark/utils.py`)
   - `LANGUAGE_TAG`: Языковые теги
   - `cleanup_code()`: Постобработка кода
   - `is_code_generation_finished()`: Early stopping

5. **IMPORT_HELPER** (`codegeex/benchmark/utils.py`)
   - Стандартные импорты для Python, Go, C++
   - Автоматически добавляются при выполнении

### Поток данных через систему

```
User Prompt
    ↓
[Optional] Language Tag Addition
    ↓
Tokenization (encode_code)
    ↓
Model Forward Pass (with KV cache)
    ↓
Logit Processing (temperature, top-k, top-p)
    ↓
Token Sampling (multinomial or greedy)
    ↓
Decoding (decode_code)
    ↓
Code Cleanup (language-specific)
    ↓
[Optional] Evaluation (test execution)
    ↓
Output / Metrics
```

### Файловая структура проекта

```
CodeGeeX/
├── codegeex/                   # Основной пакет
│   ├── __init__.py             # Главная точка входа generate()
│   ├── tokenizer/              # Токенизатор
│   │   └── tokenizer.py        # CodeGeeXTokenizer
│   ├── torch/                  # PyTorch реализация
│   │   ├── codegeex_model.py   # Архитектура модели
│   │   └── inference.py        # Функции генерации
│   ├── mindspore/              # MindSpore реализация
│   │   └── generation.py
│   ├── megatron/               # Megatron интеграция
│   │   ├── inference.py        # Distributed generation
│   │   └── code_generation_utils.py
│   ├── benchmark/              # Бенчмарки и оценка
│   │   ├── utils.py            # Утилиты (промты, cleanup)
│   │   ├── execution.py        # Выполнение тестов
│   │   ├── evaluate_humaneval_x.py
│   │   └── humaneval-x/        # Генерация для HumanEval-X
│   │       ├── generate_humaneval_x.py
│   │       └── translate_humaneval_x.py
│   └── data/                   # Утилиты данных
│       └── data_utils.py       # LANGUAGE_TAG
├── deployment/                 # Развертывание
│   ├── server_gradio.py        # Web UI сервер
│   └── example_inputs.jsonl    # Примеры для UI
├── tests/                      # Тесты
│   ├── test_inference.py       # Тестирование генерации
│   └── test_prompt.txt         # Тестовые промты
└── api/                        # API примеры
    ├── codegeex-api-example-python/
    └── codegeex-api-example-java/
```

### Ключевые точки расширения

1. **Добавление нового языка:**
   - Обновить `LANGUAGE_TAG` в `data_utils.py`
   - Добавить cleanup правила в `utils.py:cleanup_code()`
   - Добавить execution handler в `execution.py`

2. **Новый режим генерации:**
   - Создать новый prompt format (как "code translation")
   - Опционально добавить постобработку
   - Использовать существующий generation core

3. **Интеграция нового бэкенда:**
   - Реализовать `forward_step()` для бэкенда
   - Обеспечить совместимость с `get_token_stream()`
   - Примеры: torch, mindspore, megatron

4. **Кастомный sampling:**
   - Модифицировать `top_k_logits()` или создать новый
   - Интегрировать в `sample_sequence_batch()`
   - Примеры: constrained decoding, grammar-based sampling

---

## Заключение

Эта документация покрывает все основные пайплайны и схемы работы агента CodeGeeX:

1. **Code Generation Pipeline** - базовая генерация кода из промтов
2. **Code Translation Pipeline** - кроссязыковой перевод с распределенной архитектурой
3. **Benchmark Evaluation Pipeline** - автоматическое тестирование и метрики
4. **Web UI Pipeline** - интерактивный веб-интерфейс на Gradio

Все пайплайны связаны через общие компоненты (модель, токенизатор, sampling) и используют промты из `PROMPTS_DOCUMENTATION.md`. Система спроектирована модульно, что облегчает расширение и кастомизацию.

